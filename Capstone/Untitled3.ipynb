{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47d45101",
   "metadata": {},
   "source": [
    "The Effects of the Covid-19 Pandemic on Various Life Factors of Students\n",
    "\n",
    "Here is a summary of what we have covered in our exploration of the effects of the Covid-19 pandemic on students:\n",
    "\n",
    "Data Wrangling:\n",
    "\n",
    "Cleaned and prepared a dataset containing various measures of student performance and potential interventions.\n",
    "Addressed missing values, standardized numerical data, and ensured categorical data was properly encoded.\n",
    "\n",
    "Exploratory Data Analysis (EDA):\n",
    "\n",
    "Identified key trends and patterns in the data, such as the distribution of performance measures and the prevalence of certain interventions.\n",
    "Visualized relationships between different variables to understand how various factors influence student performance.\n",
    "\n",
    "Preprocessing and Training:\n",
    "\n",
    "Focused on preparing the data for modeling by handling rare classes in the target variable and encoding categorical variables.\n",
    "Used techniques like SMOTE to address class imbalance in the dataset.\n",
    "Trained and evaluated various machine learning models, including Decision Trees, Random Forests, Gradient Boosting, Logistic Regression, XGBoost, and LightGBM.\n",
    "\n",
    "We now move into the modeling process to examine the effectiveness of multiple intervention strategies, which we can use to drive our decisions regarding what interventions to recommend to schools to help their students move past the effects of the pandemic. As always, we begin by import the necessary packages, loading the dataset, and ensuring that it loads properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e5884a90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Group</th>\n",
       "      <th>T0</th>\n",
       "      <th>Scale</th>\n",
       "      <th>Measure</th>\n",
       "      <th>SD</th>\n",
       "      <th>N</th>\n",
       "      <th>T1</th>\n",
       "      <th>Scale.1</th>\n",
       "      <th>Measure.1</th>\n",
       "      <th>SD.1</th>\n",
       "      <th>N.1</th>\n",
       "      <th>T2</th>\n",
       "      <th>Scale.2</th>\n",
       "      <th>Measure.2</th>\n",
       "      <th>SD.2</th>\n",
       "      <th>N.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cataldi</td>\n",
       "      <td>Control-Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BMI</td>\n",
       "      <td>22.48</td>\n",
       "      <td>2.2</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Immediately</td>\n",
       "      <td>BMI</td>\n",
       "      <td>22.45</td>\n",
       "      <td>2.12</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waist circumference (cm)</td>\n",
       "      <td>74.87</td>\n",
       "      <td>7.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Waist circumference (cm)</td>\n",
       "      <td>74.9</td>\n",
       "      <td>7.53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Squat test (rep)</td>\n",
       "      <td>28.89</td>\n",
       "      <td>2.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Squat test (rep)</td>\n",
       "      <td>29.4</td>\n",
       "      <td>2.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Push-up test (rep)</td>\n",
       "      <td>9.13</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Push-up test (rep)</td>\n",
       "      <td>9.53</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lunge test (rep)</td>\n",
       "      <td>31.13</td>\n",
       "      <td>5.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Lunge test (rep)</td>\n",
       "      <td>31.4</td>\n",
       "      <td>6.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Author      Group  T0                     Scale Measure    SD     N  \\\n",
       "0  Cataldi  Control-Y NaN                      BMI    22.48   2.2  15.0   \n",
       "1      NaN        NaN NaN  Waist circumference (cm)   74.87  7.59   NaN   \n",
       "2      NaN        NaN NaN          Squat test (rep)   28.89   2.4   NaN   \n",
       "3      NaN        NaN NaN        Push-up test (rep)    9.13   4.2   NaN   \n",
       "4      NaN        NaN NaN          Lunge test (rep)   31.13   5.4   NaN   \n",
       "\n",
       "            T1                   Scale.1 Measure.1  SD.1   N.1   T2 Scale.2  \\\n",
       "0  Immediately                      BMI      22.45  2.12  15.0  NaN     NaN   \n",
       "1          NaN  Waist circumference (cm)      74.9  7.53   NaN  NaN     NaN   \n",
       "2          NaN          Squat test (rep)      29.4  2.56   NaN  NaN     NaN   \n",
       "3          NaN        Push-up test (rep)      9.53  4.34   NaN  NaN     NaN   \n",
       "4          NaN          Lunge test (rep)      31.4  6.07   NaN  NaN     NaN   \n",
       "\n",
       "   Measure.2  SD.2  N.2  \n",
       "0        NaN   NaN  NaN  \n",
       "1        NaN   NaN  NaN  \n",
       "2        NaN   NaN  NaN  \n",
       "3        NaN   NaN  NaN  \n",
       "4        NaN   NaN  NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Load the data\n",
    "# Get the path to the \"documents\" folder\n",
    "documents_folder = os.path.expanduser('~/Documents')\n",
    "\n",
    "# Specify the file name\n",
    "file_name = 'covid_interventions.csv'\n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(documents_folder, file_name)\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "interventions = pd.read_csv(file_path)\n",
    "\n",
    "interventions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248da619",
   "metadata": {},
   "source": [
    "Next, let's ensure that our data is nice and clean by replacing NaN values with column means for numerical columns and converting categorical columns to categorical data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e60965bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A given column is not a column of the dataframe",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'N.2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:416\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 416\u001b[0m     col_idx \u001b[38;5;241m=\u001b[39m all_columns\u001b[38;5;241m.\u001b[39mget_loc(col)\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col_idx, numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'N.2'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 47\u001b[0m\n\u001b[0;32m     44\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m pipeline\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:378\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    353\u001b[0m \n\u001b[0;32m    354\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    377\u001b[0m fit_params_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_fit_params(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m--> 378\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[0;32m    380\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:336\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    334\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[0;32m    337\u001b[0m     cloned_transformer,\n\u001b[0;32m    338\u001b[0m     X,\n\u001b[0;32m    339\u001b[0m     y,\n\u001b[0;32m    340\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    341\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    342\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params_steps[name],\n\u001b[0;32m    344\u001b[0m )\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\joblib\\memory.py:349\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:870\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 870\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    872\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:687\u001b[0m, in \u001b[0;36mColumnTransformer.fit_transform\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_transformers()\n\u001b[1;32m--> 687\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_column_callables(X)\n\u001b[0;32m    688\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_remainder(X)\n\u001b[0;32m    690\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit_transform(X, y, _fit_transform_one)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\compose\\_column_transformer.py:374\u001b[0m, in \u001b[0;36mColumnTransformer._validate_column_callables\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    372\u001b[0m         columns \u001b[38;5;241m=\u001b[39m columns(X)\n\u001b[0;32m    373\u001b[0m     all_columns\u001b[38;5;241m.\u001b[39mappend(columns)\n\u001b[1;32m--> 374\u001b[0m     transformer_to_input_indices[name] \u001b[38;5;241m=\u001b[39m _get_column_indices(X, columns)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_columns \u001b[38;5;241m=\u001b[39m all_columns\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer_to_input_indices \u001b[38;5;241m=\u001b[39m transformer_to_input_indices\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:424\u001b[0m, in \u001b[0;36m_get_column_indices\u001b[1;34m(X, key)\u001b[0m\n\u001b[0;32m    421\u001b[0m             column_indices\u001b[38;5;241m.\u001b[39mappend(col_idx)\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 424\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA given column is not a column of the dataframe\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m column_indices\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: A given column is not a column of the dataframe"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your data is loaded into a pandas DataFrame called 'interventions'\n",
    "# Define X and y\n",
    "X = interventions.drop(columns=['N.2'])  # Drop the target variable column\n",
    "y = interventions['N.2']  # Target variable\n",
    "\n",
    "# Define preprocessing steps for numeric and categorical features\n",
    "numeric_features = ['T0', 'N', 'T1', 'N.1', 'T2', 'Measure.2', 'SD.2', 'N.2']\n",
    "categorical_features = [col for col in X.columns if col not in numeric_features]\n",
    "\n",
    "# Define transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Impute missing values with most frequent category\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encode categorical features\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create a pipeline with preprocessing and the model\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef460391",
   "metadata": {},
   "source": [
    "Next, we define preprocessing steps for numeric features, including imputation and scaling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4826c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 27 candidates, totalling 54 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=KFold(n_splits=2, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         (&#x27;scaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         [&#x27;T0&#x27;,\n",
       "                                                                          &#x27;N&#x27;,\n",
       "                                                                          &#x27;T1&#x27;,\n",
       "                                                                          &#x27;N.1&#x27;,\n",
       "                                                                          &#x27;T2&#x27;,\n",
       "                                                                          &#x27;Measure.2&#x27;,\n",
       "                                                                          &#x27;SD.2&#x27;,\n",
       "                                                                          &#x27;N.2&#x27;]),\n",
       "                                                                        (&#x27;cat&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;onehot&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                         [&#x27;Scale&#x27;,\n",
       "                                                                          &#x27;SD&#x27;,\n",
       "                                                                          &#x27;Scale.1&#x27;,\n",
       "                                                                          &#x27;Measure.1&#x27;,\n",
       "                                                                          &#x27;SD.1&#x27;,\n",
       "                                                                          &#x27;Scale.2&#x27;])])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        DecisionTreeClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__max_depth&#x27;: [3, 5, 10],\n",
       "                         &#x27;classifier__min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;classifier__min_samples_split&#x27;: [2, 5, 10]},\n",
       "             verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=KFold(n_splits=2, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                                        ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         (&#x27;scaler&#x27;,\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         [&#x27;T0&#x27;,\n",
       "                                                                          &#x27;N&#x27;,\n",
       "                                                                          &#x27;T1&#x27;,\n",
       "                                                                          &#x27;N.1&#x27;,\n",
       "                                                                          &#x27;T2&#x27;,\n",
       "                                                                          &#x27;Measure.2&#x27;,\n",
       "                                                                          &#x27;SD.2&#x27;,\n",
       "                                                                          &#x27;N.2&#x27;]),\n",
       "                                                                        (&#x27;cat&#x27;,\n",
       "                                                                         Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                                          SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                                         (&#x27;onehot&#x27;,\n",
       "                                                                                          OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                                         [&#x27;Scale&#x27;,\n",
       "                                                                          &#x27;SD&#x27;,\n",
       "                                                                          &#x27;Scale.1&#x27;,\n",
       "                                                                          &#x27;Measure.1&#x27;,\n",
       "                                                                          &#x27;SD.1&#x27;,\n",
       "                                                                          &#x27;Scale.2&#x27;])])),\n",
       "                                       (&#x27;classifier&#x27;,\n",
       "                                        DecisionTreeClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;classifier__max_depth&#x27;: [3, 5, 10],\n",
       "                         &#x27;classifier__min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;classifier__min_samples_split&#x27;: [2, 5, 10]},\n",
       "             verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;T0&#x27;, &#x27;N&#x27;, &#x27;T1&#x27;, &#x27;N.1&#x27;, &#x27;T2&#x27;,\n",
       "                                                   &#x27;Measure.2&#x27;, &#x27;SD.2&#x27;,\n",
       "                                                   &#x27;N.2&#x27;]),\n",
       "                                                 (&#x27;cat&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                                  [&#x27;Scale&#x27;, &#x27;SD&#x27;, &#x27;Scale.1&#x27;,\n",
       "                                                   &#x27;Measure.1&#x27;, &#x27;SD.1&#x27;,\n",
       "                                                   &#x27;Scale.2&#x27;])])),\n",
       "                (&#x27;classifier&#x27;, DecisionTreeClassifier(random_state=42))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;T0&#x27;, &#x27;N&#x27;, &#x27;T1&#x27;, &#x27;N.1&#x27;, &#x27;T2&#x27;, &#x27;Measure.2&#x27;,\n",
       "                                  &#x27;SD.2&#x27;, &#x27;N.2&#x27;]),\n",
       "                                (&#x27;cat&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;))]),\n",
       "                                 [&#x27;Scale&#x27;, &#x27;SD&#x27;, &#x27;Scale.1&#x27;, &#x27;Measure.1&#x27;, &#x27;SD.1&#x27;,\n",
       "                                  &#x27;Scale.2&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num</label><div class=\"sk-toggleable__content\"><pre>[&#x27;T0&#x27;, &#x27;N&#x27;, &#x27;T1&#x27;, &#x27;N.1&#x27;, &#x27;T2&#x27;, &#x27;Measure.2&#x27;, &#x27;SD.2&#x27;, &#x27;N.2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Scale&#x27;, &#x27;SD&#x27;, &#x27;Scale.1&#x27;, &#x27;Measure.1&#x27;, &#x27;SD.1&#x27;, &#x27;Scale.2&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=2, random_state=42, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('preprocessor',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer()),\n",
       "                                                                                         ('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['T0',\n",
       "                                                                          'N',\n",
       "                                                                          'T1',\n",
       "                                                                          'N.1',\n",
       "                                                                          'T2',\n",
       "                                                                          'Measure.2',\n",
       "                                                                          'SD.2',\n",
       "                                                                          'N.2']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(strategy='most_frequent')),\n",
       "                                                                                         ('onehot',\n",
       "                                                                                          OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                                         ['Scale',\n",
       "                                                                          'SD',\n",
       "                                                                          'Scale.1',\n",
       "                                                                          'Measure.1',\n",
       "                                                                          'SD.1',\n",
       "                                                                          'Scale.2'])])),\n",
       "                                       ('classifier',\n",
       "                                        DecisionTreeClassifier(random_state=42))]),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'classifier__max_depth': [3, 5, 10],\n",
       "                         'classifier__min_samples_leaf': [1, 2, 4],\n",
       "                         'classifier__min_samples_split': [2, 5, 10]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the number of folds for cross-validation\n",
    "cv = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform grid search with adjusted cross-validation\n",
    "grid_search = GridSearchCV(pipeline, clf_info['params'], cv=cv, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f91bd8",
   "metadata": {},
   "source": [
    "Now, let's define classifiers with their respective hyperparameter grids. Then, we will iterate through each classifier, apply SMOTE for oversampling, and perform grid search cross-validation to find the best parameters for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e6dce2b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in cleaned data:\n",
      "Author       False\n",
      "Group        False\n",
      "T0           False\n",
      "Scale        False\n",
      "Measure      False\n",
      "SD           False\n",
      "N            False\n",
      "T1           False\n",
      "Scale.1      False\n",
      "Measure.1    False\n",
      "SD.1         False\n",
      "N.1          False\n",
      "T2           False\n",
      "Scale.2      False\n",
      "Measure.2    False\n",
      "SD.2         False\n",
      "N.2          False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Remove rows with missing or non-numeric values\n",
    "cleaned_data = interventions.dropna()\n",
    "\n",
    "# Check if there are any remaining missing or non-numeric values\n",
    "missing_values = cleaned_data.isnull().any()\n",
    "print(\"Missing values in cleaned data:\")\n",
    "print(missing_values)\n",
    "\n",
    "# Now you can proceed with fitting your pipeline using the cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0b2fe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_cleaned: (0, 16)\n",
      "Shape of y_cleaned: (0,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Assuming your cleaned dataset is stored in a DataFrame called 'cleaned_data'\n",
    "X_cleaned = cleaned_data.drop(columns=['Measure'])  # Drop the target column 'Measure' to get the feature matrix\n",
    "y_cleaned = cleaned_data['Measure']  # Select the column 'Measure' as the target vector\n",
    "\n",
    "print(\"Shape of X_cleaned:\", X_cleaned.shape)\n",
    "print(\"Shape of y_cleaned:\", y_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956f81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Step 5: Feature Scaling\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features\n",
    "interventions_scaled = scaler.fit_transform(interventions)\n",
    "\n",
    "# Convert the scaled features back to a DataFrame\n",
    "interventions_scaled_df = pd.DataFrame(interventions_scaled, columns=interventions.columns)\n",
    "\n",
    "# Check the scaled dataset\n",
    "print(interventions_scaled_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778480c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
